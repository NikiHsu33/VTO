#!/usr/bin/env python3
"""
Kaggle å¿«é€Ÿé–‹å§‹è…³æœ¬
ä¸€éµè¨­å®šä¸¦åŸ·è¡Œ PromptDresser
"""

import os
import sys
import subprocess
import zipfile
from pathlib import Path

def print_step(step_num, description):
    """æ‰“å°æ­¥é©Ÿè³‡è¨Š"""
    print(f"\n{'='*60}")
    print(f"æ­¥é©Ÿ {step_num}: {description}")
    print(f"{'='*60}")

def run_command(cmd, description):
    """åŸ·è¡Œå‘½ä»¤ä¸¦è™•ç†éŒ¯èª¤"""
    print(f"åŸ·è¡Œ: {description}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print(f"âœ… {description} æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ {description} å¤±æ•—")
        print(f"éŒ¯èª¤: {e.stderr}")
        return False

def check_environment():
    """æª¢æŸ¥ç’°å¢ƒ"""
    print_step(1, "æª¢æŸ¥ç’°å¢ƒ")
    
    # æª¢æŸ¥æ˜¯å¦åœ¨ Kaggle ç’°å¢ƒä¸­
    if os.path.exists('/kaggle/input'):
        print("âœ… æª¢æ¸¬åˆ° Kaggle ç’°å¢ƒ")
    else:
        print("âš ï¸  æœªæª¢æ¸¬åˆ° Kaggle ç’°å¢ƒ")
    
    # æª¢æŸ¥ GPU
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… GPU å¯ç”¨")
        else:
            print("âŒ GPU ä¸å¯ç”¨")
    except FileNotFoundError:
        print("âŒ nvidia-smi ä¸å¯ç”¨")

def setup_environment():
    """è¨­å®šç’°å¢ƒ"""
    print_step(2, "è¨­å®šç’°å¢ƒ")
    
    if not run_command(['python', 'kaggle_setup.py'], "ç’°å¢ƒè¨­å®š"):
        return False
    
    return True

def setup_token():
    """è¨­å®š Token"""
    print_step(3, "è¨­å®š Hugging Face Token")
    
    # æª¢æŸ¥æ˜¯å¦å·²è¨­å®š HF_TOKEN
    hf_token = os.getenv('HF_TOKEN')
    if not hf_token:
        print("âš ï¸  æœªè¨­å®š HF_TOKEN ç’°å¢ƒè®Šæ•¸")
        print("è«‹åœ¨åŸ·è¡Œæ­¤è…³æœ¬å‰è¨­å®šï¼š")
        print("import os")
        print("os.environ['HF_TOKEN'] = 'your_token_here'")
        return False
    
    print("âœ… HF_TOKEN å·²è¨­å®š")
    return True

def download_models():
    """ä¸‹è¼‰æ¨¡å‹"""
    print_step(4, "ä¸‹è¼‰é è¨“ç·´æ¨¡å‹")
    
    if not run_command(['python', 'scripts/download_models.py'], "ä¸‹è¼‰æ¨¡å‹"):
        return False
    
    return True

def patch_config():
    """ä¿®è£œé…ç½®"""
    print_step(5, "ä¿®è£œé…ç½®æª”æ¡ˆ")
    
    if not run_command(['python', 'scripts/patch_config.py'], "ä¿®è£œé…ç½®"):
        return False
    
    return True

def prepare_dataset():
    """æº–å‚™è³‡æ–™é›†"""
    print_step(6, "æº–å‚™è³‡æ–™é›†")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™é›†æª”æ¡ˆ
    kaggle_input = Path('/kaggle/input')
    if kaggle_input.exists():
        datasets = list(kaggle_input.glob('*'))
        if datasets:
            print(f"æ‰¾åˆ°è³‡æ–™é›†: {datasets}")
            
            # å°‹æ‰¾ zip æª”æ¡ˆ
            for dataset in datasets:
                zip_files = list(dataset.glob('*.zip'))
                if zip_files:
                    zip_file = zip_files[0]
                    print(f"è§£å£“è³‡æ–™é›†: {zip_file}")
                    
                    try:
                        with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                            zip_ref.extractall('data/zalando-hd-resized/')
                        print("âœ… è³‡æ–™é›†è§£å£“æˆåŠŸ")
                        return True
                    except Exception as e:
                        print(f"âŒ è³‡æ–™é›†è§£å£“å¤±æ•—: {e}")
    
    print("âš ï¸  æœªæ‰¾åˆ°è³‡æ–™é›†ï¼Œè«‹æ‰‹å‹•ä¸Šå‚³ VITON-HD æ¸¬è©¦é›†")
    print("æˆ–ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è§£å£“ï¼š")
    print("with zipfile.ZipFile('/kaggle/input/your-dataset/viton_hd_test.zip', 'r') as zip_ref:")
    print("    zip_ref.extractall('data/zalando-hd-resized/')")
    
    return False

def check_dataset():
    """æª¢æŸ¥è³‡æ–™é›†"""
    print_step(7, "æª¢æŸ¥è³‡æ–™é›†")
    
    if not run_command(['python', 'tools/check_dataset.py', 'data/zalando-hd-resized'], "æª¢æŸ¥è³‡æ–™é›†"):
        return False
    
    return True

def run_inference():
    """åŸ·è¡Œæ¨è«–"""
    print_step(8, "åŸ·è¡Œæ¨è«–")
    
    if not run_command(['python', 'kaggle_inference.py'], "åŸ·è¡Œæ¨è«–"):
        return False
    
    return True

def show_results():
    """é¡¯ç¤ºçµæœ"""
    print_step(9, "é¡¯ç¤ºçµæœ")
    
    result_dir = Path('outputs/kaggle-demo/paired')
    if result_dir.exists():
        images = list(result_dir.glob('*.png')) + list(result_dir.glob('*.jpg'))
        if images:
            print(f"âœ… æ‰¾åˆ° {len(images)} å¼µç”Ÿæˆçš„åœ–ç‰‡")
            print("åœ–ç‰‡ä½ç½®:")
            for img in images[:5]:  # åªé¡¯ç¤ºå‰5å¼µ
                print(f"  - {img}")
            
            print("\nè¦æŸ¥çœ‹åœ–ç‰‡ï¼Œè«‹åŸ·è¡Œï¼š")
            print("import matplotlib.pyplot as plt")
            print("import matplotlib.image as mpimg")
            print(f"img = mpimg.imread('{images[0]}')")
            print("plt.imshow(img)")
            print("plt.axis('off')")
            print("plt.show()")
        else:
            print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„åœ–ç‰‡")
    else:
        print("âŒ çµæœç›®éŒ„ä¸å­˜åœ¨")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ PromptDresser Kaggle å¿«é€Ÿé–‹å§‹")
    print("æ­¤è…³æœ¬å°‡è‡ªå‹•å®Œæˆæ‰€æœ‰è¨­å®šæ­¥é©Ÿ")
    
    # æª¢æŸ¥ç’°å¢ƒ
    check_environment()
    
    # è¨­å®šç’°å¢ƒ
    if not setup_environment():
        print("âŒ ç’°å¢ƒè¨­å®šå¤±æ•—")
        return
    
    # è¨­å®š Token
    if not setup_token():
        print("âŒ Token è¨­å®šå¤±æ•—")
        return
    
    # ä¸‹è¼‰æ¨¡å‹
    if not download_models():
        print("âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—")
        return
    
    # ä¿®è£œé…ç½®
    if not patch_config():
        print("âŒ é…ç½®ä¿®è£œå¤±æ•—")
        return
    
    # æº–å‚™è³‡æ–™é›†
    prepare_dataset()
    
    # æª¢æŸ¥è³‡æ–™é›†
    if not check_dataset():
        print("âŒ è³‡æ–™é›†æª¢æŸ¥å¤±æ•—")
        return
    
    # åŸ·è¡Œæ¨è«–
    if not run_inference():
        print("âŒ æ¨è«–åŸ·è¡Œå¤±æ•—")
        return
    
    # é¡¯ç¤ºçµæœ
    show_results()
    
    print("\nğŸ‰ æ‰€æœ‰æ­¥é©Ÿå®Œæˆï¼")
    print("å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥ä¸Šè¿°éŒ¯èª¤è¨Šæ¯")

if __name__ == "__main__":
    main()
